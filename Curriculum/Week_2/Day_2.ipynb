{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent AI\n",
    "\n",
    "\n",
    "![Agent AI](https://lilianweng.github.io/posts/2018-02-19-rl-overview/RL_illustration.png)\n",
    "\n",
    "*\"Try something new, add randomness to your actions. Then, compare the result to your expectation. If the result suprises you, maybe exceeded your expectations, then change your parameters to increase taking those actions in the future.\" ~ Ilya Sutskever*\n",
    "\n",
    "1. \"Try something new, add randomness to your actions.\"\n",
    "\n",
    "This is like trying a new type of ice cream flavor instead of always sticking to vanilla. You never know, you might find a new favorite! This is what we call 'exploration' in reinforcement learning, where an AI agent tries different actions to see what happens. It's like a robot exploring a new planet.\n",
    "\n",
    "\n",
    "2. \"Then, compare the result to your expectation.\"\n",
    "\n",
    "After you've tried the new ice cream flavor, you think about whether it was better, worse, or just as you expected. In reinforcement learning, this is like the AI agent checking the reward it gets after taking an action. If the ice cream was yummy, it's like getting a good reward!\n",
    "\n",
    "\n",
    "3. \"If the result surprises you, maybe exceeded your expectations...\"\n",
    "\n",
    "Sometimes you might be surprised by how much you liked the new flavor. Maybe you expected it to be just okay, but it was actually delicious! In reinforcement learning, this is like getting a higher reward than expected. It's like if the robot found a shiny gem on the planet when it was only expecting to find rocks.\n",
    "\n",
    "\n",
    "4. \"...then change your parameters to increase taking that action in the future.\"\n",
    "\n",
    "If you really liked the new flavor, you might decide to choose it more often in the future. You changed your 'ice cream picking rule' based on the new information. In reinforcement learning, this is called 'exploitation'. The AI agent adjusts its policy (which is like its 'rule book' for picking actions) to do actions that give good rewards more often. It's like the robot deciding to look for shiny gems more often, because it learned that finding gems is better than finding rocks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\John\\.conda\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import CoderSchoolAI # Imports the entire CoderSchoolAI library!\n",
    "from CoderSchoolAI import * # Imports all of the CoderSchoolAI library's things! Think of sprinkles and Cake Batter!\n",
    "from CoderSchoolAI.Environment.CoderSchoolEnvironments.SnakeEnvironment import * # We are going to use a pre-cooked Cake from the Library!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task: Generate random actions\n",
    "import numpy as np\n",
    "\n",
    "def generate_random_movements(n:int) -> List[SnakeAgent.SnakeAction]:\n",
    "    actions = []\n",
    "    for _ in range(n): # Go through the number of actions to make!\n",
    "        random_dir = # [ ENTER CODE HERE ] # This would create a random action from the possible actions!\n",
    "        actions.append(random_dir) # Add an action into the actions list\n",
    "    return actions\n",
    "\n",
    "# Generate 20 random actions and store them\n",
    "actions = generate_random_movements(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2674366786.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 12\u001b[1;36m\u001b[0m\n\u001b[1;33m    snake_env.clock.tick(snake_env.target_fps) # This is the Frame Rate Manager of the Game!\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "### Task: Run the game 50 times with Random Actions as the movements, and generate a state_action_reward dictionary!\n",
    "\n",
    "snake_env = SnakeEnv(target_fps=6, is_user_control=True, cell_size=120, height=4, width=4, verbose=True)\n",
    "num = 1\n",
    "total_reward = 0\n",
    "\n",
    "state_action_reward = {\n",
    "    # Starts of Empty!\n",
    "}\n",
    "\n",
    "# [ ENTER LOOP CODE HERE ]:\n",
    "    snake_env.clock.tick(snake_env.target_fps) # This is the Frame Rate Manager of the Game!\n",
    "    snake_env.render_env() # Let's see the environment!\n",
    "    action = generate_random_movements(1)[0]\n",
    "    reward, finished = snake_env.snake_agent._move_snake(action) # This moves our Snake in that Direction and returns a reward!\n",
    "    \n",
    "    # [ ENTER CODE HERE ] # Update our state_action_reward dictionary with the correct reward!\n",
    "    \n",
    "    \n",
    "    # Maitenence of the Environment!\n",
    "    if not finished:\n",
    "        total_reward += reward\n",
    "        snake_env.update_observation_variables()\n",
    "        for name, obs in snake_env.ObsAttributes.items():\n",
    "            obs.update_func()\n",
    "    else: # Resets the Environment\n",
    "        print(\"Total reward:\", total_reward)\n",
    "        snake_env.reset()\n",
    "    num = (num+1) % len(actions) # Resets the current Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Playground:\n",
    "\n",
    "\"\"\"\n",
    "Todays Goals:\n",
    " - See the reward stuff\n",
    " - Modify the above code to collect a bunch of data\n",
    " - Use the found data to Generalize!\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
