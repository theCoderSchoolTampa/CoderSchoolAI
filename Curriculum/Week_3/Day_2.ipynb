{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "from torch import nn, optim, functional\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def train_mnist(model, epochs=5, test_every_ep=90, learning_rate=0.003):\n",
    "\n",
    "    # This makes our data easier to work with for the Network\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    # Download/Load Data from Online Hub\n",
    "    trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "    trainloader = th.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Same for Testing Data\n",
    "    testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "    testloader = th.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "    test_iter = iter(testloader)\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        step = 0   \n",
    "        for images, labels in trainloader:\n",
    "            # Flatten the images\n",
    "            step+=1\n",
    "            labels = th.nn.functional.one_hot(labels, num_classes=10).float()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if step % 30 == 0:\n",
    "                print('Loss:', loss.item())\n",
    "            running_loss += loss.item()\n",
    "            if step % test_every_ep == 0:\n",
    "                model.eval()\n",
    "                with th.no_grad(): # Lets Perform a Check to see how Accurate our model is\n",
    "                    image, labels = next(test_iter) # Get next Training Set\n",
    "                    labels_one_hot = th.nn.functional.one_hot(labels, num_classes=10).float() # Get MNIST labels for the Training Set\n",
    "                    output = model(image) # Perform Forward Pass\n",
    "                    loss = criterion(output, labels_one_hot) # Grade the Output\n",
    "                    predictions = th.argmax(output, dim=1) # Check to see what it predicted\n",
    "                    correct = (predictions == labels).sum().item() # See how many it got right\n",
    "                    total = labels.size(0) \n",
    "                print(\"Accuracy: {:.2f}%\".format(correct/total*100))\n",
    "                print('Testing Loss:', loss.item())\n",
    "        print(f\"Epoch {epoch+1} - Training loss: {running_loss/len(trainloader)}\")\n",
    "    print(\"Training completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Network...\n",
      "Comiled Block:  CoderSchoolAI.Neural.Blocks.InputBlock.InputBlock>,\n",
      "\n",
      "Comiled Block:  CoderSchoolAI.Neural.Blocks.ConvBlock.ConvBlock>,\n",
      "  (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (5): ReLU()\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (8): ReLU()\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Flatten(start_dim=1, end_dim=-1)\n",
      "\n",
      "Comiled Block:  CoderSchoolAI.Neural.Blocks.OutputBlock.OutputBlock>,\n",
      "  (0): Linear(in_features=3136, out_features=10, bias=True)\n",
      "  (1): Identity()\n",
      "\n",
      "Loss: 0.0885368213057518\n",
      "Loss: 0.059029243886470795\n",
      "Loss: 0.03415431082248688\n",
      "Accuracy: 82.81%\n",
      "Testing Loss: 0.04149077460169792\n",
      "Loss: 0.025527354329824448\n",
      "Loss: 0.02069271169602871\n",
      "Loss: 0.022012749686837196\n",
      "Accuracy: 95.31%\n",
      "Testing Loss: 0.01905834674835205\n",
      "Loss: 0.020307345315814018\n",
      "Loss: 0.01581302471458912\n",
      "Loss: 0.015156736597418785\n",
      "Accuracy: 100.00%\n",
      "Testing Loss: 0.016091417521238327\n",
      "Loss: 0.01887359470129013\n",
      "Loss: 0.014275474473834038\n",
      "Loss: 0.012067199684679508\n",
      "Accuracy: 98.44%\n",
      "Testing Loss: 0.019779697060585022\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m net\u001b[39m.\u001b[39mcompile()\n\u001b[0;32m     24\u001b[0m \u001b[39m# Call the function to train the model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m train_mnist(net)\n",
      "Cell \u001b[1;32mIn[14], line 35\u001b[0m, in \u001b[0;36mtrain_mnist\u001b[1;34m(model, epochs, test_every_ep, learning_rate)\u001b[0m\n\u001b[0;32m     33\u001b[0m labels \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mone_hot(labels, num_classes\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     34\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 35\u001b[0m output \u001b[39m=\u001b[39m model(images)\n\u001b[0;32m     36\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, labels)\n\u001b[0;32m     37\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\John\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\John\\.conda\\envs\\pytorch\\lib\\site-packages\\CoderSchoolAI\\Neural\\Net.py:58\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__compiled:\n\u001b[0;32m     57\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot forward a network that has not been compiled.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock_network(x)\n",
      "File \u001b[1;32mc:\\Users\\John\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\John\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\John\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\John\\.conda\\envs\\pytorch\\lib\\site-packages\\CoderSchoolAI\\Neural\\Blocks\\ConvBlock.py:82\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtuple\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m::]) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_shape:\n\u001b[0;32m     81\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConvBlock.forward() expects a matrix of shape Batch Size x \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_shape\u001b[39m}\u001b[39;00m\u001b[39m, Provided Shape: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m::])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule(x)\n\u001b[0;32m     83\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_connections \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m ( \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_connections, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_connections) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m ) \u001b[39mor\u001b[39;00m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_connections\u001b[39m.\u001b[39md_type \u001b[39m==\u001b[39m Block\u001b[39m.\u001b[39mType\u001b[39m.\u001b[39mJOIN:\n\u001b[0;32m     84\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\John\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\John\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from CoderSchoolAI.Environment.CoderSchoolEnvironments.SnakeEnvironment import *\n",
    "from CoderSchoolAI.Environment.Attributes import *\n",
    "from CoderSchoolAI.Neural.Blocks import *\n",
    "from CoderSchoolAI.Neural.Net import *\n",
    "\n",
    "image = ObsAttribute(name=\"img\", space=BoxType(-1, 1, shape=(1, 28, 28)))\n",
    "input_block = InputBlock(in_attribute=image, is_module_dict=False)\n",
    "\n",
    "# Define the ConvBlock which acts as a convolutional layer for processing the game state.\n",
    "# The depth of 3 represents the number of convolutional layers in this block.\n",
    "conv_block = ConvBlock(input_shape=input_block.in_attribute.space.shape, num_channels=1, depth=4)\n",
    "lin_block = LinearBlock(input_size=conv_block.output_size, output_size=conv_block.output_size/2, hidden_size=conv_block.output_size, num_hidden_layers=3, dropout=0.2)\n",
    "# Define the OutputBlock that will decide the next action to take based on the current game state.\n",
    "# The num_classes corresponds to the number of possible actions the snake can take (up, down, left, right).\n",
    "out_block = OutputBlock(input_size=conv_block.output_size, num_classes=10)\n",
    "\n",
    "# Initialize the network and add the blocks\n",
    "net = Net(device='cuda')\n",
    "\n",
    "net.add_block(input_block)\n",
    "net.add_block(conv_block)\n",
    "net.add_block(out_block)\n",
    "net.compile()\n",
    "\n",
    "print(out_block.device)\n",
    "# Call the function to train the model\n",
    "train_mnist(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CoderSchoolAI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
